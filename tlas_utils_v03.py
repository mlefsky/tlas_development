import numpy as np
import matplotlib.pyplot as plt
import laspy
import pickle
import os
import subprocess
import rasterio
import rioxarray
import dask 
from dask.utils import SerializableLock
import datetime
import matplotlib
# Nate asked what my code generally looks like, so I am sharing the 
# code I wrote to generate data products for Alaska.  The details of the
# processing steps are less important that the overall system structure. 
# In designing this version of my system, I have assumed that PDAL and GDAL 
# will be important to the work, as will some standard python libraries 
# such as rasterio, laspy, etc.
#
# As you probably know, keeping track of 
# intermediate and final datasets and the methods used to create 
# them is a PITA. One often has 10's or even 100's of datasets 
# generated by analyses (some documented, usually with some that are not) 
# whose provinence is only known by the analyst. I do a lot of work 
# comparing the results of data analyses, so there are many files
# generated, e.g. for picking an optimal segmentation routine to identify 
# individual trees. 
#
# The system I developed helps the individual analyst keep track of 
# their work and also allows for a unique "chain-of-custody" to know 
# exactely what was to create various datasets. This allows us to be 
# confident that the results we are giving clients are the correct ones
# _and_ allows future analysts to see exactly what steps were used in
# processing, which can be one part of our strategy for showing that 
# Teren has addressed the problem of showing that our methods aren't tied 
# to individual personnel.
# 
# In the system I use, each step in the processing chain generates 
# intermediate and final data products that follow a standard file naming 
# system implemented by the routines themselves and returns a structure 
# with the name of the files and parameters used to create them.
#
# This is especially useful for this work because I anticipate that 
# much of our processing pipeline will (as I said above) involve running
# external programs. PDAL, for instance, can be acessed using a python
# api, but the documentation isn't very good and most users seem to go 
# the route of generarting json files and running then using the pdal 
# application in bash/cmd. In that case, we need to keep track of
# any json or .bash/.bat scripts being generated and the command used  
# to generate/process them. I do this by extending the filename 
# scheme to include the json and bash files being created and record 
# their names and locations in a structure returned from the function.
#
# All functions work off a single filename for either the base laz file
# or of an important derivative (e.g. DTM)
# That filename is passed to each function which modifies it  
# to include details of the "trial_id" and the type of data product 
# produced. The trial_id keyword allows you to assign a unique id
# to every series of data products so that it and any intermediate data products don't
# get confused with each other. The single "trial_id" keyword can 
# itself be used to store multiple pieces of information separated
# with delimeters. For segmentation the files might look like: 
#
#        tile_xx_xx_ttt_ttt_pdtm.tif
#
# where ttt_ttt summarizes the test being done and/or some set of parameters
# 
# All functions return a dict with 
#    a <list> of the resulting json/bash commands (in Popen style) 
#    a single text command dervied from the <list> formatted with " ".join(commands)
#    an out_filename indicating the file that was created (can be more than one)
#    a json file (if applicable) to send to pdal
#    a "type" code to indicate what analysis created the file (e.g. tlas_dtm,tlas_dsm,...)
#    a las_directory to show the base directory of the input and output files
#    a "trial_id" code (if applicable) indicating a code to keep data products and
#     analyses separate and identifiable. 
# 
# If, as with tlas_chm and tlas_cover, the function calls one or more other functions, 
# the structure returned from each functions is included with the top level return dictionary
# so there is a record of dependencies. So, for a calculation of the canopy height model (CHM)
# the output structure includes all the details of the CHM analysis, as well as all the
# details of the DSM and DTM processing as keys in the dictionary:
#
# cmd_list  <class 'list'>
# cmd       <class 'str'>
# script    <class 'str'>
# out_filename <class 'str'>
# json_file <class 'str'>
# type      <class 'str'>
# trial_id     <class 'str'>
# las_directory    <class 'str'>
# dtm_outstruct <class 'dict'>     <------------
# dsm_struct <class 'dict'>     <------------
# bash_filename <class 'str'>
# bach_command <class 'str'> command to be used with bash - used
#   to put both pdal and bash calls in the same form

# Note: I use the presence of "outstruct" in an outstruct key name to identify 
# output structure that are included as part of an analysis. As such, don't
# use keys with "outstruct" in them
#
# Eventually, the hierarchy of analysis functions would include data management tools 
# that 1) match table/vector/raster data sources and 2) tools to generate final statistics.  
# Statistical results are also stored in the heiarchy along with all the information to 
# identify the intent of the analysis via the trial_id keyword.
# Other than manual operations (which I avoid as much as possible), any
# library or package can be used as long as there is a python wrapper function that returns 
# the details of the analysis sources, methods, and output location. 
#q
# At present, the code I use has a high meatball coefficient- basically it's improvised
# code that isn't very sophisticated. I'm sure that there is a more elegant way to 
# implement these features in python but for now I needed to get results quickly and 
# demonstrate the basic idea of what I am looking for. I'm hoping that implementing this
# system will be seen as advantageous to Teren and that it will receive resources to 
# develop as general solution as possible (e.g. using decorators)
#
# TTD:  I'd like to have the Date/Time of analysis and run duration of each process
#       The Name and Last modification date/time of the code being run.
#	Run duration of analysis
#       For some products, we need to wait to get results from various routines and we should 
#       have code that watches for the end of a process and then moves on.  
#   Determine dependencies to allow multiple steps at the same time rathewr than
#   wait until each job is done in order.
# More....

# pdtm = PDAL DTM
# pdsm = PDAL DSM
# and so on....

###########################################################################################
# Helper Functions
###########################################################################################

def return_res(filename):
    tmp=rasterio.open(filename)
    res=tmp.transform()
    res=res[0]
    return res

def clean_dirname(dirname):
    dirname_out=dirname
    if dirname[-1] != "/":  
        dirname_out=dirname_out+"/"
    return(dirname_out)

def clean_filename_parts(filename,dirname):
    filename_out=filename.replace(dirname,"")
#    if filename_out[-1] == "_":  
#        filename_out= filename_out[:len(filename_out)-1]
#    if filename_out[-1] == "_":  
 #       filename_out= filename_out[:len(filename_out)-1]
    return(filename_out)

def current_time():
    now = datetime.datetime.now() # current date and time
    date_time = now.strftime("%Y%m%d:%H%M%S")
    return(date_time)



from matplotlib.gridspec import GridSpec

def index_to_coordinate(index, extent, origin):
    """Return the pixel center of an index."""
    left, right, bottom, top = extent

    hshift = 0.5 * np.sign(right - left)
    left, right = left + hshift, right - hshift
    vshift = 0.5 * np.sign(top - bottom)
    bottom, top = bottom + vshift, top - vshift

    if origin == 'upper':
        bottom, top = top, bottom

    return {
        "[0, 0]": (left, bottom),
        "[M', 0]": (left, top),
        "[0, N']": (right, bottom),
        "[M', N']": (right, top),
    }[index]


def get_index_label_pos(index, extent, origin, inverted_xindex):
    """
    Return the desired position and horizontal alignment of an index label.
    """
    if extent is None:
        extent = lookup_extent(origin)
    left, right, bottom, top = extent
    x, y = index_to_coordinate(index, extent, origin)

    is_x0 = index[-2:] == "0]"
    halign = 'left' if is_x0 ^ inverted_xindex else 'right'
    hshift = 0.5 * np.sign(left - right)
    x += hshift * (1 if is_x0 else -1)
    return x, y, halign


def get_color(index, data, cmap):
    """Return the data color of an index."""
    val = {
        "[0, 0]": data[0, 0],
        "[0, N']": data[0, -1],
        "[M', 0]": data[-1, 0],
        "[M', N']": data[-1, -1],
    }[index]
    return cmap(val / data.max())


def lookup_extent(origin):
    """Return extent for label positioning when not given explicitly."""
    if origin == 'lower':
        return (-0.5, 6.5, -0.5, 5.5)
    else:
        return (-0.5, 6.5, 5.5, -0.5)


def set_extent_None_text(ax):
    ax.text(3, 2.5, 'equals\nextent=None', size='large',
            ha='center', va='center', color='w')


def plot_imshow_with_labels(ax, data, extent, origin, xlim, ylim,cmap=None,vmin=None,vmax=None,
                            title=None,xtitle=None,ytitle=None):
#    fig = plt.figure(tight_layout=False,figsize=(6,4))
#    """Actually run ``imshow()`` and add extent and index labels."""
#    print(title,xtitle,ytitle)
    im = ax.imshow(data, origin=origin, extent=extent,aspect='auto',cmap=cmap,vmin=vmin,vmax=vmax)
    font = {'family':'serif','color':'Black','size':15}
    plt.xlabel(xtitle,fontdict = font)
    plt.ylabel(ytitle,fontdict = font)
    plt.title(title,fontdict = font)

    ax.ticklabel_format(style='plain')
    # extent labels (left, right, bottom, top)
    left, right, bottom, top = im.get_extent()
#    print(    left, right, bottom, top)
    if xlim is None or top > bottom:
        upper_string, lower_string = 'top', 'bottom'
    else:
        upper_string, lower_string = 'bottom', 'top'
    if ylim is None or left < right:
        port_string, starboard_string = 'left', 'right'
        inverted_xindex = False
    else:
        port_string, starboard_string = 'right', 'left'
        inverted_xindex = True
#    bbox_kwargs = {'fc': 'w', 'alpha': .75, 'boxstyle': "round4"}
#    ann_kwargs = {'xycoords': 'axes fraction',
#                  'textcoords': 'offset points',
#                  'bbox': bbox_kwargs}
#    ax.annotate(upper_string, xy=(.5, 1), xytext=(0, -1),
#                ha='center', va='top', **ann_kwargs)
#    ax.annotate(lower_string, xy=(.5, 0), xytext=(0, 1),
#                ha='center', va='bottom', **ann_kwargs)
#    ax.annotate(port_string, xy=(0, .5), xytext=(1, 0),
#                ha='left', va='center', rotation=90,
#                **ann_kwargs)
#    ax.annotate(starboard_string, xy=(1, .5), xytext=(-1, 0),
#                ha='right', va='center', rotation=-90,
#                **ann_kwargs)
#    ax.set_title(f'origin: {origin}')

    # index labels
#    for index in ["[0, 0]", "[0, N']", "[M', 0]", "[M', N']"]:
#        tx, ty, halign = get_index_label_pos(index, extent, origin,
#                                             inverted_xindex)
#        facecolor = get_color(index, data, im.get_cmap())
#        ax.text(tx, ty, index, color='white', ha=halign, va='center',
#                bbox={'boxstyle': 'square', 'facecolor': facecolor})
    if xlim:
        ax.set_xlim(*xlim)
    if ylim:
        ax.set_ylim(*ylim)
    

def generate_imshow_demo_grid(extents, xlim=None, ylim=None):
    N = len(extents)
#    fig = plt.figure(tight_layout=True,figsize=(6,4))
#    fig.set_size_inches(6, N * (11.25) / 5)
    gs = GridSpec(N, 5, figure=fig)

    columns = {'label': [fig.add_subplot(gs[j, 0]) for j in range(N)],
               'upper': [fig.add_subplot(gs[j, 1:3]) for j in range(N)],
               'lower': [fig.add_subplot(gs[j, 3:5]) for j in range(N)]}
    x, y = np.ogrid[0:6, 0:7]
    data = x + y

    for origin in ['upper', 'lower']:
        for ax, extent in zip(columns[origin], extents):
            plot_imshow_with_labels(ax, data, extent, origin, xlim, ylim)

    columns['label'][0].set_title('extent=')
    for ax, extent in zip(columns['label'], extents):
        if extent is None:
            text = 'None'
        else:
            left, right, bottom, top = extent
            text = (f'left: {left:0.1f}\nright: {right:0.1f}\n'
                    f'bottom: {bottom:0.1f}\ntop: {top:0.1f}\n')
        ax.text(1., .5, text, transform=ax.transAxes, ha='right', va='center')
        ax.axis('off')
    return columns#


###########################################################################################
# Main Functions
###########################################################################################

def lastool_voxelize(fname,skip_lastools=False):
    voxel_fname=fname.replace(".laz","_voxel.laz").replace(".las","_voxel.las")
    voxel_fname_txt=voxel_fname.replace(".laz",".txt").replace(".las",".txt")
    cmd1="wine /home/ubuntu/lastools/bin/lasvoxel64.exe -v -i "+fname+" -o "+voxel_fname
    cmd2="wine /home/ubuntu/lastools/bin/las2txt.exe -cpu64 -i "+voxel_fname+" -parse xyzi -sep comma -o "+voxel_fname_txt+" -header pound"
    #print(cmd1)
    #print(cmd2)
    if (skip_lastools == False):
        os.system(cmd1)
        os.system(cmd2)

    txt_voxels=np.loadtxt(voxel_fname_txt,delimiter=",",comments="#")
    x=0 ; y=1 ; z=2 ; i=3
    minx=np.min(txt_voxels[:,x]) ; maxx=np.max(txt_voxels[:,x]) 
    miny=np.min(txt_voxels[:,y]);maxy=np.max(txt_voxels[:,y])
    minz=np.min(txt_voxels[:,z]) ; maxz=np.max(txt_voxels[:,z])

    if(minz < 0):
        minz=0
        
    xindex=np.arange(minx,maxx+1,)
    yindex=np.arange(miny,maxy+1)
    zindex=np.arange(minz,maxz+1)
    nuvalues_x=len(np.unique(txt_voxels[:,x])) ; nuvalues_y=len(np.unique(txt_voxels[:,y])) ; nuvalues_z=len(np.unique(txt_voxels[:,z]))
    res_voxels_x=np.round((maxx-minx)/(nuvalues_x-1)*100)/100
    res_voxels_y=np.round((maxy-miny)/(nuvalues_y-1)*100)/100
    res_voxels_z=np.round((maxz-minz)/(nuvalues_z-1)*100)/100
    
    #print("VOXELS")
    #print(np.round((maxz-minz)/(nuvalues_z-1)))
    #print(res_voxels_x,maxx,minx,nuvalues_x)
    #print(res_voxels_y,maxy,miny,nuvalues_y)
    print(res_voxels_z,maxz,minz,nuvalues_z)
    x_transform=np.round((txt_voxels[:,x]-minx)/res_voxels_x).astype(np.int32)
    y_transform=np.round((txt_voxels[:,y]-miny)/res_voxels_y).astype(np.int32)
    z_transform=np.round((txt_voxels[:,z]-minz)/res_voxels_z).astype(np.int32)

    z_transform=np.clip(z_transform, 0, 10000,)
    
    max_xindex=max(x_transform)
    max_yindex=max(y_transform)
    max_zindex=max(z_transform)
    min_xindex=min(x_transform)
    min_yindex=min(y_transform)
    min_zindex=min(z_transform)
    print(">>>>>>>>>>>>>>>>>>>>>")
    print(min(x_transform),max(x_transform))
    print(min(y_transform),max(y_transform))
    print(min(z_transform),max(z_transform))
#    plt.scatter(x_transform[::10000],z_transform[::10000])
    voxels=np.zeros(((max_xindex-min_xindex)+1,(max_yindex-min_yindex)+1,(max_zindex-min_zindex)+1))
    ix=np.logical_and((x_transform > 0) , (y_transform > 0)  ,  (z_transform > 0))
    print(len(list(ix)))
    print(x_transform.shape,y_transform.shape,z_transform.shape,txt_voxels[ix,i].shape)
#    voxels[x_transform[ix],y_transform[ix],z_transform[ix]]=txt_voxels[:,i]
    voxels[x_transform,y_transform,z_transform]=txt_voxels[:,i]
    voxel_sum=np.sum(voxels,2)
    print(voxel_sum.shape)
    for ivx in range(0,max_zindex+1):
        voxels[:,:,ivx]=voxels[:,:,ivx]/voxel_sum
    voxels=np.clip(voxels,0,1)
    print("DM",np.sum(voxel_sum))
       
    return({"voxels":voxels,"xrange":[minx,maxx],"yrange":[miny,maxy],"zrange":[minz,maxz],
         "xindex":xindex,"yindex":yindex,"zindex":zindex})

def first_nonzero(arr, axis, invalid_val=-1):
    mask = np.rot90(arr!=0,2)
    tmp=np.where(mask.any(axis=axis), mask.argmax(axis=axis), invalid_val)
    return(np.flip(tmp))


def plot_voxel_slice(slice,voxel_struct,title=None,xtitle=None,ytitle=None,show_image=True,show_plot=True,plot_color="r"):
    rainbow=matplotlib.colormaps['rainbow'].resampled(256)
    rainbow_mod=rainbow(np.linspace(0,1,256))
    rainbow_mod[0,:]=np.array([0,0,0,0])
    newcmap=matplotlib.colors.ListedColormap(rainbow_mod)
    maxv=np.percentile(slice[slice>0],95)
    extent=(voxel_struct['xrange'][0],voxel_struct['xrange'][1],voxel_struct['zrange'][0],
            voxel_struct['zrange'][1])
            
    print(extent)
    if show_image:
        plt.clf()
        imgplot=plt.imshow(np.rot90(slice),cmap=newcmap,vmin=0,vmax=maxv,aspect='auto')

#        tmp=plot_imshow_with_labels(plt, slice, extent,"lower",None,None,
#                                    cmap=newcmap,vmin=0,vmax=maxv,
#                                    title=title,xtitle=xtitle,ytitle=ytitle)

    if show_plot:
        slice=np.rot90(slice,3)
        slice_maxz=first_nonzero(slice,0)
        plt.plot(np.flip(slice_maxz),color=plot_color)

    return(slice_maxz)

#    print(type(tmp))

def tlas_voxel_zscale(filename,dtm_filename,zmin,scalefactor,las_directory):
    cmds=[]
#####################################################################################################
    cmd_1=""" 
{  "pipeline":[
    {
        "filename":"$1"
    },\n"""

    cmds.append(cmd_1.replace("$1",las_directory+filename))
######################################tlas_voxel_zscalevoxel###############################################################
    cmd_2="""{ "type":"filters.hag_dem",
        "raster":"$2"
    },"""
    #\n{"type":"filters.range",

#    cmd_2=cmd_2+"\"limits\":\"HeightAboveGround["+str(limits[0])+":"+str(limits[1])+"]\"},"
    cmds.append(cmd_2.replace("$2",las_directory+dtm_filename))
#####################################################################################################
    cmd_3=\
"""
{ "type": "filters.ferry","dimensions":"Z=>PassiveZ"},
{ "type": "filters.assign","value":"Z=(((PassiveZ-$minz)/$scalev)+HeightAboveGround)"},
    
"""
    print(zmin)
    cmds.append(cmd_3.replace("$minz",str(zmin)).replace("$scalev",str(scalefactor)))

        
#####################################################################################################
    cmd_3=\
"""
{
        "type":"writers.las",
        "filename":"$3",        
        "compression":"lasperf",
        "extra_dims":"PassiveZ=double"}]}
""" 
#####################################################################################################
    out_filename=filename.replace(".laz","_hag_scale_"+str((round(scalefactor*10)/10)).replace(".","")+".laz")
    cmd_3=cmd_3.replace("$3",las_directory+out_filename)
    cmds.append(cmd_3)
    json_filename=las_directory+filename.replace(".laz","_hag_scale_"+str((round(scalefactor*10)/10)).replace(".","")+".json")
#    print(">>>>>>>>>>>>>")#
#    print(cmds)
    
    with open(json_filename, 'w') as f:
        for c in cmds:
            f.write(c)
##            print(c)
    return((json_filename,las_directory+out_filename))


def tlas_pdtm(las_filename_in,las_directory_in,trial_id_in,res,**kwargs):
# Makes a dtm from a las file using the PDAL smrf alogrithm
# Primarily used for comparing multiple processing techniques without 
# needing to produce multiple DTMs that are optimized for "best"
# results
#    print("res_pdtm: ",res)

 #   print("LF:",las_filename_in)
    las_directory=clean_dirname(las_directory_in)
    las_filename=clean_filename_parts(las_filename_in,las_directory)
    
    las_filename=las_directory+las_filename
    trial_id=clean_filename_parts(trial_id_in,las_directory)

#    out_tif_filename=las_filename.replace(trial_id,"").replace(".tif",trial_id+".tif")
    
#####################################################################################################
    cmds=\
"""                                                        
{
            "pipeline": [
{
                "type": "readers.las",
                "filename": "$1"
            },
            {
                "type":"filters.assign",
                "assignment":"Classification[:]=0"
            },
            {
                "type":"filters.elm"
            },
            {
                "type":"filters.outlier",
                "method":"statistical",
                "mean_k":8,
                "multiplier":3.0
            },
            {
                "type":"filters.smrf",
                "window":18,
                "threshold":0.30,
                "scalar":0.95
            },
            {
                "type":"filters.range",
                "limits":"Classification[2:2]"
            },
            {
                "type": "writers.gdal",
                "filename": "$2",
                "output_type": "mean",
                "gdaldriver": "GTiff",
                "resolution": $res, 
                "binmode":true,
                "nodata":"-9999",
                "radius": $res,
                "data_type": "float32"
            }

            ]
    }
"""
#####################################################################################################

    
    dtm_out_filename=las_filename.replace(".las",trial_id+"_pdtm.tif").replace(".laz",trial_id+"_pdtm.tif")
    cmds=cmds.replace("$1",las_filename)
    cmds=cmds.replace("$2",dtm_out_filename)
    cmds=cmds.replace("$res",str(res))
    cmds=cmds.replace("\\","\\\\")
    #print("DOF",dtm_out_filename)        

    json_filename=las_directory+'tlas_dtm_'+las_filename_in.replace(".las","").replace(".laz","")+trial_id+'.json'
    #print(">>>>>>>>>>>>>",json_filename)
    with open(json_filename, 'w') as f:
        f.write(cmds)
    cmd=["pdal", "pipeline",las_directory+"tlas_dtm"+trial_id+".json"] 
    bash_command=" ".join(cmd)

    out={"cmd_list":cmd,"cmd":"".join(cmd),"out_filename":dtm_out_filename,
         "json_file":json_filename,"type":"dtm","las_filename":las_filename,
         "las_directory":las_directory,"script_runtime":current_time(),"res":res,
         "bash_command":bash_command}
    return(out)

def tlas_pdsm(las_filename_in,las_directory_in,trial_id_in,res,**kwargs):
#    print("res_pdsm: ",res)
    las_directory=clean_dirname(las_directory_in)
    las_filename=clean_filename_parts(las_filename_in,las_directory)
    las_filename=las_directory+las_filename
    #print("DSM",las_filename)
    trial_id=clean_filename_parts(trial_id_in,las_directory)
    out_filename=las_filename.replace(".laz",'_pdsm.tif').replace(".las",'_pdsm.tif')
#    las_filename=las_filename.replace(trial_id,"")
    #print("OFF",out_filename,las_filename)    
     
      
###############################################################################
    cmds="""
{
    "pipeline":[
        {
            "type": "readers.las",
            "filename": "$1"},
        {
            "type":"filters.range",
            "limits":"returnnumber[0:1]"
        },

        {
            "type": "writers.gdal",
            "filename":"$2",
            "output_type":"mean",
            "gdaldriver":"GTiff",
            "resolution": $res,
            "radius": $res,
            "data_type": "float32",
            "binmode":true,
            "nodata":"-9999"

        }
    ]
}
"""

###############################################################################

    cmds=cmds.replace("$1",las_filename)
    cmds=cmds.replace("$2",out_filename)
    cmds=cmds.replace("$res",str(res))
    cmds=cmds.replace("\\","\\\\")
 
    

    with open(las_directory+'tlas_dtm_'+las_filename_in.replace(".las","").replace(".laz","")+trial_id+'.json', 'w') as f:
      f.write(cmds)
#    bash_command="pdal pipeline "+las_directory+'tlas_dsm'+trial_id+'.json'
    bash_command="pdal pipeline "+'tlas_dsm'+trial_id+'.json'
#    #print(">>>>>>>>",out_filename)
    out={"cmd_list":cmds,"cmd":" ".join(cmds),"out_filename":out_filename,
         "json_file":las_directory+"tlas_dsm"+trial_id+".json","type":"dsm","trial_id":trial_id,
         "las_directory":las_directory,"script_runtime":current_time(),"res":res,
         "bash_command":bash_command}
#    for k in out:
#        #print(k,out[k])

    return(out)


def tlas_chm(las_filename_in,las_directory_in,trial_id_in,in_res,hlimits=None,
             read_dtm="",read_dsm=""):

    las_directory=clean_dirname(las_directory_in)
    las_filename=clean_filename_parts(las_filename_in,las_directory)
    trial_id=clean_filename_parts(trial_id_in,las_directory)
    res=in_res
#    print("FNAME",res,read_dtm)
    if(read_dtm != ""):        
        dtm_outstruct=tlas_read(read_dtm,las_directory)
        dtm_out_filename=las_directory+dtm_outstruct['out_filename']
        res=dtm_outstruct['res']
#    print("FNAME",res,read_dtm)
        #print("TRUE1",dtm_out_filename,dtm_outstruct['out_filename'])

#    print("res_chm: ",res)


    if(read_dsm != ""):        
        dsm_outstruct=tlas_read(las_filename,las_directory)
        dsm_out_filename=dsm_outstruct['out_filename']
#        res_dsm=dsm_outstruct['res']
        #print("TRUE2",dsm_out_filename)
#        print("res_chm: ",res_dsm)
        

#    if (res != 0 and res_dsm != 0):
#        if res != res_dsm:
#            print("dtm and dsm are read from existing files with different resolutions")
#        if (res != 0) and (res_dsm ==0):
#            res=res
#        if (res == 0) and (res_dsm !=0):
#            res=res_dsm

    if res == 0:
        res=in_res

    if read_dtm == "":
        dtm_outstruct=tlas_pdtm(las_filename,las_directory,trial_id,res)
        dtm_out_filename=dtm_outstruct['out_filename']

    if read_dsm == '':        
       dsm_outstruct=tlas_pdsm(las_filename,las_directory,trial_id,res)
       dsm_out_filename=dsm_outstruct['out_filename']
        
#    print("dof",las_filename)
#    print("TMP@",dtm_out_filename)
    chm_out_filename= dtm_out_filename.replace("_pdtm",trial_id+"_chm").replace("_dtm","_chm")
#    print("TMP@",dsm_out_filename)        peinr(">>>>",)
 
#    print("TMP@",chm_out_filename)
#    print("TMP@",trial_id)

#####################################################################################################
    if (hlimits == None):
        func='"B-A"'
    else: 
        func='\"numpy.clip(B-A,'+str(hlimits[0])+","+str(hlimits[1])+")\""
#####################################################################################################
    
    cmd=['gdal_calc.py',' -A '+dtm_out_filename,' -B '+dsm_out_filename,' --overwrite --calc='+func+ ' --outfile '+chm_out_filename+" --extent=intersect"]
    print("")
#    print(" ".join(cmd))
    bash_filename=las_directory+'tlas_chm'+trial_id+'.bash'

#    with open(bash_filename, 'w') as f:
#        for ix,c in enumerate(cmds):
#            f.write(c+"\n")
#            print(c)
#            print("\n")
#        f.write(" ".join(cmd))
#        #print(" ".join(cmd))

    bash_command=" ".join(cmd)
  
    out={"cmd_list":cmd,"cmd":"".join(cmd),"script":"","out_filename":las_directory+dtm_out_filename,
        "json_file":"","type":"chm","trial_id":trial_id,"las_filename":las_filename,
        "las_directory":las_directory,"dtm_outstruct":dtm_outstruct,
        "dsm_outstruct":dsm_outstruct,"bash_command":bash_command,"script_runtime":current_time(),
        "bash_filename":bash_filename}
    
    return(out)
    
def tlas_pdensity(las_filename,las_directory,trial_,res,limits=None,limit_code="",read_dtm="",*kwargs):

#    print("res_pdtm: ",res)
    print(">>>>>",las_filename)
    if read_dtm == "":
        dtm_filename=las_filename.replace(".las",trial_+"_pdtm.tif").replace(".laz",trial_+"_pdtm.tif")
    else:
        dtm_filename=read_dtm
#        dtm_filename=read_dtm.replace('.tif',trial_+".tif")
#    print(">>>",dtm_filename)

    if len(limit_code) != 0:
        if limit_code[1] != "":
            limit_code="_"+limit_code
#    print('limit_code: '+limit_code)
#    print(type(limit_code),type(trial_),type(las_directory))
    out_filename=las_filename.replace(".las","_density"+limit_code+trial_+".tif").\
    replace(".laz","_density"+str(limit_code)+str(trial_)+".tif")
#    print('of',out_filename)
    #print("???????????",dtm_filename)
    cmds=[]
#####################################################################################################
    cmd_1="""
{  "pipeline":[
    {
        "filename":"$1"
    },\n"""

    cmds.append(cmd_1.replace("$1",las_directory+las_filename))
#####################################################################################################
    if (limits!=None):
        cmd_2="""{ "type":"filters.hag_dem",
            "raster":"$2"
        },\n{"type":"filters.range",
        """        
        cmd_2=cmd_2+"\"limits\":\"HeightAboveGround["+str(limits[0])+":"+str(limits[1])+"]\"},"
        cmds.append(cmd_2.replace("$2",dtm_filename))
        
#####################################################################################################
    cmd_3=\
"""
{
        "type":"writers.gdal",
        "filename":"$3",        
        "dimension":"Z",
        "data_type":"float32",
        "output_type":"count",
        "resolution": $res,
        "binmode":true}]}
""" 
#####################################################################################################
    cmd_3=cmd_3.replace("$3",las_directory+out_filename)
    cmd_3=cmd_3.replace("$res",str(res))
    cmds.append(cmd_3)
    
    json_filename=las_directory+'mk_density_'+out_filename+"_"+limit_code+"_"+trial_+'.json'
    json_filename=json_filename.replace("__","_")
    json_filename=json_filename.replace("__","_")
    bash_script=""
    out={"cmd_list":cmds,"cmd":" ".join(cmds),"out_ filename":out_filename,
        "json_file":json_filename,"type":"density_"+limit_code,"trial_":trial_,
        "las_directory":las_directory,"filename":out_filename,"bash_cmd":bash_script,"limit_code":limit_code,
        "bash_command":"pdal pipeline "+json_filename,res:res}
    print("]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]")
    with open(json_filename, 'w') as f:
        for c in cmds:
            f.write(c)
            print(">",c)

#    print(">>>>",json_filename)
    return(out)


def tlas_cover(las_filename,dtm_filename,las_directory,trial_,res=3.28):
#    print("res_cover: ",res)

    cmds=[]
    pdensity_struct=tlas_pdensity(las_filename,las_directory,trial_,res,read_dtm=dtm_filename,limits=None)
    print()
    print()
    print()
    
    print(pdensity_struct)
    print()
    print()
    print()
    print()
    print()
    print("==========================================================",las_filename,las_directory,trial_,res,dtm_filename)
    cmds.append("pdal pipeline "+
                pdensity_struct['json_file'])


    pdensity_lt1_struct=tlas_pdensity(las_filename,
            las_directory,trial_,res,read_dtm=dtm_filename,limits=[-2,1],limit_code="lt1")
    print()
    print()
    print()
    print()
    print(pdensity_lt1_struct)
    print()
    print()
    print()
    print()
    cmds.append("pdal pipeline "+pdensity_lt1_struct['json_file'])
    
    filename_A=las_directory+pdensity_struct['filename']
    filename_B=pdensity_lt1_struct['filename']
    
    ofilename=las_directory+filename_B.replace('.tif','_cover.tif').replace("_lt1","").replace("_density","")

    i=rasterio.open(dtm_filename)
    bb=i.bounds
    #print(bb)
    left=bb[0]
    bottom=bb[1]
    right=bb[2]
    top=bb[3]
    projwin="--projwin "+str(left)+" "+str(top)+" "+str(right)+" "+str(bottom)+ " "
    #print("PW: ",projwin)

#####################################################################################################
    cmd=['gdal_calc.py','--quiet ','-A ',filename_A,
         ' -B ',filename_B,' --overwrite --calc="numpy.clip((B/A),0,1)" ',' --outfile '+ofilename,projwin+" --type='Float32'"]
#         ' -B ',filename_B,' --overwrite --calc="numpy.clip((B/A),0,1)" ',' --outfile '+ofilename,"--extent=intersect  --type='Float32'"]
#####################################################################################################

    #print(">>>>>>>>>>>>>>>>>",cmd)
    cmds.append(" ".join(cmd))

    bash_filename=las_directory+'mk_cover_'+las_filename.replace(".las","").replace(".laz","")+trial_+'.bash'


    with open(bash_filename, 'w') as f:
        for ix,c in enumerate(cmds):
            f.write(c+"\n")
            print(c)
            print("\n")

    bash_command=" ".join(cmds)
    out=""

    out={"cmd_list":"","cmd":"","script":cmds,"out_filename":ofilename,
        "json_file":"","type":"cover","trial_":trial_,
        "las_directory":las_directory,"pdensity_outstruct":pdensity_struct,
        "pdensity_lt1_outstruct":pdensity_lt1_struct,"bash_filename":bash_filename,
        "bash_command":bash_command}

    return (out)


def tlas_read(new_filename,directory_in):  
#    print("new",new_filename)
    directory=clean_dirname(directory_in)
    out_filename= new_filename#.replace(".las","_pdtm.tif").replace(".laz","_pdtm.tif")
    dataset = rasterio.open(directory_in+new_filename)
    transform=dataset.transform
#    print("tr",transform)
#Affine(30.0, 0.0, 358485.0,,,
#       0.0, -30.0, 4265115.0)

    out={"cmd_list":"","cmd":"","script":"","out_filename":out_filename,
    "json_file":"","type":"external_file_read","trial_id":"","script_runtime":current_time(),
    "las_directory":directory,"las_filename":new_filename,"res":transform[0],
    "bash_command":"# external file read"}
    return(out)

def collect_bash_commands(dictionary: dict,out,verbose=False):
    for key in dictionary:
        value = dictionary[key]
        if "outstruct" in key:
            dummy=collect_bash_commands(value,out)
        else:
            if key=="bash_command":
                out.append(value)
#                print(value)
                return

#==============================================================================
#==============================================================================
#==============================================================================
#==============================================================================
#==============================================================================
#==============================================================================
#==============================================================================


def image_to_table(image_fname,skip1,csv_fname,res):
    import geopandas
    import pandas as pd
    import rasterio
    import matplotlib.pyplot as plt
    from shapely import points
    from rasterio.plot import show  
    import numpy as np
    import glob

    res_code=str(res).replace(".","")
#    file_list,band_names=tile_files(res)
    
    ds = rasterio.open(image_fname, "r") #Read the raster

    a = ds.read(1) #Read as a numpy array
    height, width = a.shape #Find the height and width of the array
    cols, rows = np.meshgrid(np.arange(width), np.arange(height)) 
    xs, ys = rasterio.transform.xy(ds.transform, rows, cols) 
    xcoords = np.array(xs)
    ycoords = np.array(ys)

    unique, counts = np.unique(a, return_counts=True)
    counts = dict(zip(unique, counts))

    xindex, yindex = np.where(a==1)

    pts=points(xcoords,y=ycoords)
    pts2=pts.reshape(-1)
    skip=int(np.round(((len(pts2))/skip1)))
    pts3=pts2[::skip]

    print("pts",len(pts))

    gdf = geopandas.GeoDataFrame(list(range(len(pts3))), geometry=pts3)

    coord_list = [(x, y) for x, y in zip(gdf["geometry"].x, gdf["geometry"].y)]
#    print()
    ds=rasterio.open(image_fname)
#    src_io=np.squeeze(ds.read().astype(rasterio.float32))
    print(ds.meta)
    print("lbn",len(band_names),len(file_list))
    print("BNBNNBBN",band_names)
    for ix,band in enumerate(band_names):
        print("ix",int(ix+1),band)
#        print(list(ds.sample(coord_list,indexes=int(ix)+1)))
        print("GDF")
        out=list(ds.sample(coord_list,indexes=int(ix)+1))
        gdf[band]=out
#        out['trial']
        df = pd.DataFrame(gdf)  
        csv_file=image_fname.replace(".tif",".csv")
        df.to_csv(csv_file, index=False)

    print("REPROCESSING OF OUTPUT CSV")
#   REFORMAT OUTPUT FILE 
    with open(csv_file, 'r') as file:
      filedata = file.read()
    
# Replace the target string
    filedata = filedata.replace('[', '').replace(']', '').replace('nan', str(-9999.0))
    
    # Write the file out again
    with open(csv_file, 'w') as file:
      file.write(filedata)
   
    return gdf


def merge_files(file_list,band_names,ofilename,las_directory):

    no_data=-9999

    with rasterio.open(las_directory+file_list[1]) as src0:
        meta = src0.meta

    print("lbn2",len(band_names),len(file_list))
    # Update meta to reflect the number of layers

    height1,width1=src0.shape
    meta.update(count = len(file_list))
    meta.update(height=height1)
    meta.update(width=width1)
    meta.update(transform=src0.meta['transform'])
    meta.update(no_data= no_data)
             
#    print("meta_shop",meta['transform'])

    
    #print(">>>",ofilename)    
#    for id in range(1,1+len(file_list)):
#        #print(id,type(id))
#    print(ofilename)

    flag=0
    with rasterio.open(las_directory+ofilename, 'w',**meta) as dst:
        dst.nodata = no_data
#        print("DST",dst.meta)
        
        for id in range(1,1+len(file_list)):
            #print(type(id))
            layer=file_list[int(id)-1]
            #print("ID",int(id),layer)  img
            #print("/home/ubuntu/time_trials/"+ofilename)
            with rasterio.open(las_directory+layer,"r",**meta) as src1:

                tmp=src1.read(1)

#                tmp[tmp==(-9999)]= no_data
#                tmp[tmp==0]=no_data
                tmp[tmp>1000000]= no_data
                tmp[tmp<(-1000000)]= no_data
                tmp[tmp==float('inf')]=no_data
                tmp[tmp==float(0)]=no_data
                tmp[tmp==float('nan')]=no_data

#                tmp[tmp==Inf]=no_data
#                tmp[tmp=="no_data"]=no_data
                dst.write_band(int(id),tmp)
                dst.set_band_description(id,band_names[int(id)-1])
                # if (flag==0):
                #     mask=tmp != -9999
                # else:
                #     mask=mask & tmp != -9999
 
                # dst.write_mask(tmp)

                                                       
#    with rasterio.open(ofilename, 'r',**meta) as dst:
        #print('DST',dst.meta)
    #print("done")
    #with open("/home/ubuntu/time_trials/alltif.txt","r") as file:
    #    filenames=file.readlines()
    return()





def tile_files(res):

    # file_list=["tile_66_136_sub_01_chm.tif",
    # "tile_66_136_sub_01_sub_01_cover.tif",
    # "tile_66_136_sub_01_density_lt1_sub_01.tif",
    # "tile_66_136_sub_01_density_sub_01.tif",
    # "tile_66_136_sub_01_pdsm.tif",
    # "tile_66_136_sub_01_pdtm.tif",
    # "tile_66_136_sub_02_chm.tif",
    # "tile_66_136_sub_02_sub_02_cover.tif",
    # "tile_66_136_sub_02_density_lt1_sub_02.tif",
    # "tile_66_136_sub_02_density_sub_02.tif",
    # "tile_66_136_sub_02_pdsm.tif",
    # "tile_66_136_sub_02_pdtm.tif",
    # "tile_66_136_sub_03_chm.tif",
    # "tile_66_136_sub_03_sub_03_cover.tif",
    # "tile_66_136_sub_03_density_lt1_sub_03.tif",
    # "tile_66_136_sub_03_density_sub_03.tif",
    # "tile_66_136_sub_03_pdsm.tif",
    # "tile_66_136_sub_03.pdtm.tif",
    # "tile_66_136_sub_04_chm.tif",
    # "tile_66_136_sub_04_sub_04_cover.tif",
    # "tile_66_136_sub_04_density_lt1_sub_04.tif",
    # "tile_66_136_sub_04_density_sub_04.tif",
    # "tile_66_136_sub_04_pdsm.tif",
    # "tile_66_136_sub_04_pdtm.tif"]

    res_code=str(res).replace('.','')

    file_list1=['tile_66_136_sub_01_$res_code_sub_01_chm.tif',
    'tile_66_136_sub_01_sub_01_cover.tif',
    'tile_66_136_sub_01_density_lt1_sub_01.tif',
    'tile_66_136_sub_01_density_sub_01.tif',
    'tile_66_136_sub_01_pdsm.tif',
    'tile_66_136_sub_01_$res_code_pdtm.tif',

    'tile_66_136_sub_02_$res_code_sub_02_chm.tif',
    'tile_66_136_sub_02_sub_02_cover.tif',
    'tile_66_136_sub_02_density_lt1_sub_02.tif',
    'tile_66_136_sub_02_density_sub_02.tif',
    'tile_66_136_sub_02_pdsm.tif',
    'tile_66_136_sub_02_$res_code_pdtm.tif',

    'tile_66_136_sub_03_$res_code_sub_03_chm.tif',
    'tile_66_136_sub_03_sub_03_cover.tif',
    'tile_66_136_sub_03_density_lt1_sub_03.tif',
    'tile_66_136_sub_03_density_sub_03.tif',
    'tile_66_136_sub_03_pdsm.tif',
    'tile_66_136_sub_03_$res_code_pdtm.tif',

    'tile_66_136_sub_04_$res_code_sub_04_chm.tif',
    'tile_66_136_sub_04_sub_04_cover.tif',
    'tile_66_136_sub_04_density_lt1_sub_04.tif',
    'tile_66_136_sub_04_density_sub_04.tif',
    'tile_66_136_sub_04_pdsm.tif',
    'tile_66_136_sub_04_$res_code_pdtm.tif']             
             
    file_list=[x.replace('$res_code',res_code) for x in file_list1]
        
    band_names1=["sub_01_chm",
    "sub_01_cover",
    "sub_01_density_lt1",
    "sub_01_density",
    "sub_01_pdsm",
    "sub_01_pdtm",
    "sub_02_chm",
    "sub_02_cover",
    "sub_02_density_lt1",
    "sub_02_density",
    "sub_02_pdsm",
    "sub_02_pdtm",
    "sub_03_chm",
    "sub_03_cover",
    "sub_03_density_lt1",
    "sub_03_density",
    "sub_03_pdsm",
    "sub_03_pdtm",
    "sub_04_chm",
    "sub_04_cover",
    "sub_04_density_lt1",
    "sub_04_density",
    "sub_04_pdsm",
    "sub_04_pdtm"]

    band_names=[x.replace('$res_code',res_code) for x in band_names1]

    return(file_list,band_names)



def do_sub_analysis(las_directory,files,res):

    res_code=str(res).replace(".","")
    #start=time.time(3P
    outcmds=[]
    trial_id=""
    for filename in files:
        print(filename)
#        las_directory="/home/ubuntu/time_trials/trial_656/"

        # setup files for two runs of tlas_cover and tlas_chm
 
#        dtm_filename=dtm_filename.replace("$res_code",res_code)
#        print(dtm_filename)
        dtm_filename=""
        chm_outstruct=tlas_chm(filename,las_directory,trial_id,res,hlimits=[0,60])#read_dtm=dtm_filename)
        outfile_bash=las_directory+filename.replace('.las',trial_id+'_chm.bash').replace('.laz',trial_id+'_chm.bash')

        out=[]        
        bash_commands=[]
        collect_commands=collect_bash_commands(chm_outstruct,out)
        
#=============================================================================
        with open(outfile_bash, 'w') as f:  
            for o in out: 
                f.write(o+"\n")
                
        outcmds.append("bash "+outfile_bash)
        dtm_filename=las_directory+filename.replace(".las","_pdtm.tif").replace(".laz","_pdtm.tif")

        cover_outstruct=tlas_cover(filename,dtm_filename,las_directory,trial_id,res=res)
        outfile_bash=las_directory+filename.replace('.las',trial_id+'_cover.bash').replace('.laz',trial_id+'_script.bash')
        collect_commands=collect_bash_commands(cover_outstruct,out)

        with open(outfile_bash, 'w') as f:  
  #           print(">>>>>>>>>>>>>",outfile_bash)
            bash_commands.append(outfile_bash)
            for o in out: 
                f.write(o+"\n")

        with open(las_directory+"runall.sh","w") as f:
            for b in outcmds: #bash_commands:
                f.write(b+" \n")

    #print("#outcmds")
#    print(outcmds)

    
#=============================================================================
            

#==============================================================================
#==============================================================================
#==============================================================================
#==============================================================================
#==============================================================================
#==============================================================================
#==============================================================================

def mk_voxels(filename,dtm_filename,las_directory,skip_lastools=False):
   las_directory="/home/ubuntu/time_trials/"
   dtm_filename="tile_66_136_dtm.tif"
   (json_file,hag_filename)=tlas_voxel_zscale(filename,dtm_filename,8153,4,las_directory) 
   if skip_lastools == False:
       os.system("pdal pipeline "+json_file)
   voxels=lastool_voxelize(hag_filename,skip_lastools=skip_lastools)
   return(voxels)


def main(skip_lastools=False):   
    
    laz_files=["nodup_100_22.laz","nodup_512_11.laz","nodup_669_8.laz","nodup_985_4.laz"]
    las_directory="/home/ubuntu/density_comparison_v2/"

    do_sub_analysis(las_directory,laz_files,3.28)
     # 
 
    return()   
 
#    filename="tile_66_136_sub_01.laz"
#    dtm_filename="tile_66_136_dtm.tif"
 
#    tmp1=mk_voxels(filename,dtm_filename,las_directory,skip_lastools=True)
 #   
 #   filename="tile_66_136_sub_02.laz"
 #   las_directory="/home/ubuntu/time_trials/"
 #   dtm_filename="tile_66_136_dtm.tif"
 #   tmp2=mk_voxels(filename,dtm_filename,las_directory,skip_lastools=True)

 #   diff=tmp1['voxels'][:,400,:]-tmp2['voxels'][:,400,:]
 #   print("minmax ",np.min(diff),np.max(diff))
 #   return((tmp1,tmp2,diff)) 


#
#               tile_66_136_sub_01_hagscale_voxel.txt
    
    print(lastool_voxelize('/home/ubuntu/time_trials/tile_66_136_sub_01_hag_scale_40.laz'))  
 
    
    print(lastool_voxelize('/home/ubuntu/time_trials/tile_66_136_sub_01_hag_scale_40.laz'))

    return()
          
 #    re=6.56
    res=6.56
#    res=1.64
    res_code=str(res).replace('.',"")

    file_list,band_names=tile_files(res)
    las_directory="/home/ubuntu/time_trials/trial_$res_code/"
    las_directory=las_directory.replace("$res_code",res_code)

#    tmp=do_sub_analysis(las_directory,res)

#    tmp=merge_files(file_list,band_names,"tile_66_136_"+res_code+"_stack.tif",las_directory)
 @   dummy=image_to_table(las_directory+"tile_66_136_"+res_code+"_stack.tif",10000,
                         las_directory+"tile_66_136_"+res_code+"_stack.tif",res)
#    print(dummy)

          
#if __name__ == "__main__":  

    # execute only if run as a scrip
 #   tmp=main()



#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=
#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=

